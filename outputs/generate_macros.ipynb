{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "channels = ['CE', 'CHE', 'GC', 'NSC', 'SMT']\n",
    "\n",
    "filename='/data/wiay/2297403c/amaze_model_select/AMAZE_project_resources/test_production_runs/continuous_GWTC-3/output_seed12.hdf5'\n",
    "\n",
    "result_files={'cont':filename,'disc':filename,'KDE':filename}\n",
    "\n",
    "betas={'cont':dict.fromkeys(channels, 'val'),\\\n",
    "        'disc':dict.fromkeys(channels, 'val'),\\\n",
    "        'KDE':dict.fromkeys(channels, 'val')}\n",
    "betasup={'cont':dict.fromkeys(channels, 'val'),\\\n",
    "        'disc':dict.fromkeys(channels, 'val'),\\\n",
    "        'KDE':dict.fromkeys(channels, 'val')}\n",
    "betaslow={'cont':dict.fromkeys(channels, 'val'),\\\n",
    "        'disc':dict.fromkeys(channels, 'val'),\\\n",
    "        'KDE':dict.fromkeys(channels, 'val')}\n",
    "\n",
    "#chi_b, alpha_CE median and quantiles for continuous inference\n",
    "#bayes factors between chi_b and alpha_CE models for KDE and flows?\n",
    "# KL divergences between KDE and flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inference in ['cont', 'disc', 'KDE']:\n",
    "    result = h5py.File(result_files[inference])\n",
    "    if inference == 'cont':\n",
    "        beta_samps = result['model_selection']['samples']['block0_values'][:,2:]\n",
    "    else:\n",
    "        beta_samps = result['model_selection']['samples']['block1_values'][:,:]\n",
    "    for cidx, channel in enumerate(channels):\n",
    "        betas[inference][channel] = np.median(beta_samps)\n",
    "        betasup[inference][channel] = np.quantile(beta_samps, .95)-np.median(beta_samps)\n",
    "        betaslow[inference][channel] = np.median(beta_samps)-np.quantile(beta_samps,.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_macros.sty', 'w') as macros_file:\n",
    "    for channel in channels:\n",
    "        for inference in ['cont', 'disc', 'KDE']:\n",
    "            command = '{\\Beta'+channel+inference+'}{'+str(betas[inference][channel])+'}'\n",
    "            macros_file.write(f'\\\\newcommand{command}\\n')\n",
    "            command = '{\\Beta'+channel+inference+'up}{'+str(betasup[inference][channel])+'}'\n",
    "            macros_file.write(f'\\\\newcommand{command}\\n')\n",
    "            command = '{\\Beta'+channel+inference+'low}{'+str(betaslow[inference][channel])+'}'\n",
    "            macros_file.write(f'\\\\newcommand{command}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('amaze')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05013be2d79c0e90f66cc6cc6fb2349c533de9d1dc87de817e9686faf5df3efe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
